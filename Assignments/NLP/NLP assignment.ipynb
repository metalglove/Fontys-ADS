{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('nlpplease': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ee40ac2d9d94b947205e0669a45d6e2c063eeb49adef47071ce5e42677967e8c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "After attending the workshops by Olaf Janssen [\\[1\\]](#References) on Natural Language Processing (NLP), <br>\n",
    "it is time to start playing with state-of-the-art NLP pre-trained models, such as BERT (and derivatives such as ALBERT and RoBERTa), GPT-2 or XLNET. <br>\n",
    "<br>\n",
    "The assignment is to first pick a NLP task (such as Q&A, search engine, chatbot, classification, etc.). <br>\n",
    "Then to choose a context wherein this task is being ran (such as a game, a service, smart applications, etc.). <br>\n",
    "And, build it! <br>\n",
    "The idea is that the student will be working with pre-trained models and that the focus is primarily on designing the right pipeline for the problem at hand. <br>\n",
    "Endlessly fine-tuning the model is not a priority in this assignment; the goal is to demonstrate that the student understands how a NLP task is build up and can apply NLP techniques. <br>\n",
    "The result must be an interactive prototype that tackles a specific NLP task."
   ]
  },
  {
   "source": [
    "# Introduction\n",
    "This notebook will contain my NLP learning journey throughout the assignment. <br>\n",
    "Before diving into the assignment for the workshop, I will first experiment with NLP pipelines. <br>\n",
    "I do this because it helps me better understand how NLP libraries are used. <br>\n",
    "Afterwards, I will explain the task I have chosen and how I plan to approach it. <br>\n",
    "Lastly, I will conclude my learning journey with an interactive version of my NLP model. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "In this section useful libraries are imported which are used in most data science projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# sets the path to the home directory of this repository so other modules can be imported. \n",
    "project_path = os.getcwd()\n",
    "root_path = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "assert root_path.endswith(\"Fontys-ADS\"), \"The root path does not end with Fontys-ADS: \" + root_path \n",
    "sys.path.insert(0, root_path)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "transformers.logging.set_verbosity(40)\n",
    "# set the seed for reproducible results.\n",
    "np.random.seed(56)\n",
    "tf.random.set_seed(56)\n",
    "\n",
    "# optionally, set TensorFlow to use the GPU with all available memory.\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "source": [
    "Information about the installed packages:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "transformers==3.5.0\nnumpy==1.19.2\ntensorflow==2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(f'transformers=={transformers.__version__}')\n",
    "print(f'numpy=={np.__version__}')\n",
    "print(f'tensorflow=={tf.__version__}')"
   ]
  },
  {
   "source": [
    "# Hands-On with NLP pipelines\n",
    "For the experimenting with NLP pipelines I found the library transformers from huggingface [\\[2\\]](#References). <br>\n",
    "It has a simple to use API and has support for many NLP models. <br>\n",
    "I will experiment with a few different NLP tasks using the pipeline API."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "source": [
    "## Text generation pipeline\n",
    "For text generation, I started with creating a pipeline with a GPT2 (small) pre-trained model. <br>\n",
    "But the small GPT2 model did not produce good enough outputs. So, I swapped out the small model for the large model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen = pipeline(\"text-generation\", model=\"gpt2-large\")"
   ]
  },
  {
   "source": [
    "And tried a few different text-generation continuations...."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'Many moons ago it had looked as if this island, in these waters, might belong to us. We now know, however, that what we took from the islands of the sea must have been of great value. And we were able to draw from this island a rich vein of gold. And it was known among us, in those days, as a place where the gold was in greatest demand. We did not have the means to mine it ourselves, so we sent people along the coast to find'"
     },
     "metadata": {}
    }
   ],
   "source": [
    "result = text_gen(\"Many moons ago\", max_length=100)\n",
    "display(result[0]['generated_text'])"
   ]
  },
  {
   "source": [
    "The pipeline resulted in some interesting continuations:\n",
    "- <b> Providing \"In a forgotten land, far far away, \", resulted in: </b> <br> \n",
    "\"In a forgotten land, far far away, are the only things left: the walls from which I was to die, and the sun that shone when I slept. Therein lies a world of promise. And it I have known all\"\n",
    "- <b> Providing \"Have you read Olaf's NLP blog post?\", resulted in: </b> <br> \n",
    "\"Have you read Olaf's NLP blog post? It's the most useful thing I've read on NLP, ever. (And you should read it.)\\n\\nAdvertisements\\n\\nLike this: Like Loading... Related\\n\\nPosted in Unc\"\n",
    "- <b> Providing \"In a galaxy far away, the sith are preparing for\", resulted in: </b> <br> \n",
    "\"In a galaxy far away, the sith are preparing for a grand festival. The Sith Lord, Darth Vader, is about to make his grand return. As a reward for his master's treachery, Vader himself is given the title of Darth Vader\"\n",
    "\n",
    "Not every continuation makes sense. It also feels like it is just spitting out text it has read before from blog posts, or the like."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Question & Answer pipeline\n",
    "For the question and answer task, I can also provide a context for the model to answer questions on. <br>\n",
    "For this model, I chose the most popular question-answering model on huggingface's website."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"question-answering\", model=\"deepset/bert-large-uncased-whole-word-masking-squad2\")"
   ]
  },
  {
   "source": [
    "The context I provide is about a band I was listening to during the making of this notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = r\"\"\"\n",
    "The band Æther Realm has a song called The Sun, The Moon, The Stars which is 20 minutes in length.\n",
    "The Sun, The Moon, The Stars is most known for its lengthy guitar riffs and melodies.\n",
    "But I also like the song called The Fool which is only 4 minutes in length.\n",
    "After playing the 20 minute song, I played the rest of the album.\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "The questions I ask below all belong to the context, so they should be answerable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Answer: 'The Sun, The Moon, The Stars', score: 0.9546, start: 40, end: 68\n",
      "Answer: 'Æther Realm', score: 0.9729, start: 10, end: 21\n",
      "Answer: 'I played the rest of the album.', score: 0.0283, start: 296, end: 327\n",
      "Answer: 'The Fool', score: 0.9815, start: 218, end: 226\n",
      "Answer: 'The Fool', score: 0.0494, start: 218, end: 226\n",
      "Answer: 'The Sun, The Moon, The Stars', score: 0.0472, start: 40, end: 68\n"
     ]
    }
   ],
   "source": [
    "result = nlp(question=\"What is the name of the song which is 20 minutes in  length?\", context=context)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n",
    "result = nlp(question=\"What is the name of the band which has a song of 20 minutes in length?\", context=context)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n",
    "result = nlp(question=\"What happened after listening to The Sun, The Moon, The Star?\", context=context)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n",
    "result = nlp(question=\"Which song did I like?\", context=context)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n",
    "result = nlp(question=\"What is the name of the shortest song?\", context=context)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n",
    "result = nlp(question=\"What is the name of the lengthiest song?\", context=context)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "source": [
    "The questions below are not explained in the context and should not be answerable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Answer: 'Æther Realm', score: 0.0, start: 10, end: 21\n",
      "Answer: 'Æther Realm', score: 0.2439, start: 10, end: 21\n"
     ]
    }
   ],
   "source": [
    "result = nlp(question=\"Who is the lead singer of the band?\", context=context)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n",
    "result = nlp(question=\"What genre is this band?\", context=context)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "source": [
    "The six questions it was able to answer, it did succesfully. <br>\n",
    "The two questions it should not be able to answer, failed to be answered. <br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Translation pipeline\n",
    "For the translation pipeline, there are also many models available. <br>\n",
    "I have chosen the T5 model to translate English to German. <br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline(\"translation_en_to_de\", model=\"t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Mein Fahrrad ist gestohlen.'"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "translation = translator(\"My bike is stolen.\", max_length=40)\n",
    "translation[0]['translation_text']"
   ]
  },
  {
   "source": [
    "I have not had German in years, but I am fairly sure that this translation is correct."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# NLP Assignment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Conclusion\n",
    "soontm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# References\n",
    "\\[1\\] Janssen, O. (2020). NLP Introduction Overview. Olafjanssen.github.io. Retrieved from https://olafjanssen.github.io/nlp-workshop/. <br>\n",
    "\\[2\\] Wolf et al (2019). HuggingFace's Transformers: State-of-the-art Natural Language Processing. Huggingface.co. Retrieved from https://huggingface.co/transformers/. <br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}